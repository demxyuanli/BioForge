### 项目任务书（调整版）

**项目名称**：PrivateTune Pro 云端版私有大模型微调客户端软件开发  

**版本**：1.1（框架调整版）  
**日期**：2026年1月30日  

#### 1. 项目背景与概述
随着大型语言模型（如Qwen系列和DeepSeek系列）在专业领域的应用日益深化，用户需要一种安全、便捷的工具，将自有专业文档转化为私有化模型，以生成高质量的专业内容（如建议书、技术方案、学术论文）。本项目旨在开发一款桌面客户端软件（PrivateTune Pro 云端版），专为无本地GPU硬件的用户设计，实现从文档投喂、数据标注到云端微调的完整闭环。软件完全依赖云端微调服务，确保数据隐私和低门槛部署。

当前（2026年），Alibaba Cloud DashScope提供Qwen系列官方SFT/LoRA微调支持；Fireworks.ai和Together AI平台深度支持DeepSeek系列（包括V3/R1）的云端fine-tuning，性能优异且成本可控。

#### 2. 项目目标
- 构建一个用户友好的桌面客户端，支持专业用户快速注入领域知识，形成私有模型。
- 实现零本地硬件依赖，全流程云端微调。
- 支持生成结构化专业输出（如建议书、方案、论文），并确保数据隐私。
- 最终交付可独立运行的跨平台软件（Windows、macOS、Linux）。

#### 3. 功能需求
软件分为四大核心模块，形成自动化闭环：

1. **知识仓储模块**
   - 支持上传PDF、Word、Markdown、图像等格式文档。
   - 自动OCR识别、文本清洗、段落切分。
   - 利用RAG技术结构化长文档为原子知识点。
   - 支持用户标记（Tagging），如[格式:建议书]、[知识:专业术语]。
   - 提供自动脱敏处理功能。

2. **智能标注助手模块**
   - 自动生成指令对/问答对（基于云端基础模型调用）。
   - 支持人工打分（1-5分）、偏好比较、负向标记。
   - 支持DPO格式数据生成，简化RLHF。
   - 半自动化循环：模型生成→人工修正→迭代优化。
   - 数据质量统计与导出（JSONL标准格式）。

3. **微调引擎模块**
   - 纯云端模式，支持以下平台与模型（基于2026年最新支持）：
     | 目标模型       | 云端平台                  | 微调方式      | 备注                  |
     |----------------|---------------------------|---------------|-----------------------|
     | Qwen3系列     | Alibaba Cloud DashScope  | SFT/LoRA     | 官方支持，稳定高效   |
     | DeepSeek-V3/R1| Fireworks.ai / Together AI| LoRA/SFT     | 高性能，成本优化     |
   - 统一API抽象（集成LiteLLM），支持一键切换平台。
   - 任务监控：进度、费用估算、日志查看。
   - 支持增量微调和小规模测试。

4. **效果评测与内容生成模块**
   - 侧向对比（微调前vs后），集成自动化指标。
   - 调用微调后专用endpoint生成专业内容。
   - 模板库：预设“建议书”“技术方案”“论文”等模式，支持自定义Prompt。
   - 输出编辑、导出（Word/PDF）与版本历史。

#### 4. 非功能需求
- **隐私与安全**：API密钥本地加密存储；数据集上传前强制脱敏；审计日志。
- **性能**：标注与预处理纯CPU运行；云端调用响应延迟<5s。
- **兼容性**：跨平台桌面应用，无GPU要求。
- **成本控制**：内置费用预估工具，优先LoRA微调（单次数百元）。
- **用户体验**：向导式界面、多版本管理、动态仪表盘（费用、进度）。

#### 5. 界面设计要求
- 主工作空间：数据中心、训练实验室、生产调优、隐私中心。
- 向导式流程引导新手。
- 动态看板显示云平台余额、微调进度。
- 简洁专业风格，避免复杂操作。

#### 6. 技术栈要求（调整后）
- **前端**：首选Tauri（2.0及以上版本，轻量、安全、高性能跨平台框架）；备选Electron（适用于团队熟悉Node.js生态的场景）。
- **后端处理**：Python + LangChain/LlamaIndex（文档处理） + LiteLLM（API统一）。
- **数据库**：本地SQLite（标注数据） + Chroma（向量存储，轻量）。
- **其他**：无本地微调框架依赖。Tauri后端通过IPC或外部进程调用Python服务，确保高效集成。

#### 7. 交付物
- 完整源代码（Git仓库）。
- 可执行安装包（跨平台）。
- 用户手册与API配置指南。
- 测试报告（包括首次微调案例）。
- 维护文档（平台切换与框架扩展指南）。

#### 8. 时间计划（建议）
- **阶段1（2-4周）**：需求确认与原型设计（知识仓储 + 标注助手，使用Tauri快速搭建UI原型）。
- **阶段2（4-6周）**：核心功能开发（微调引擎 + 云平台集成）。
- **阶段3（2-4周）**：界面优化、测试与评测模块。
- **阶段4（1-2周）**：交付与培训。
- 总周期：3-4个月（可根据资源调整）。

#### 9. 验收标准
- 成功上传文档并生成至少200条优质指令对。
- 完成一次完整云端微调（Qwen或DeepSeek），生成专业内容质量经人工评估达标。
- 软件稳定运行，无数据泄露风险。
- 符合本任务书所有功能与非功能需求，特别是Tauri框架下的性能与安全标准。

